# Estrategia de MigraciÃ³n Oracle â†’ PostgreSQL

**Proyecto:** phantomx-nexus
**Fecha de definiciÃ³n:** 2025-01-05
**Ãšltima actualizaciÃ³n:** 2025-01-05
**Estado:** Estrategia definida - Lista para implementaciÃ³n
**Modelo:** Claude Sonnet 4.5 (Claude Code Pro)

---

## ğŸ¯ Contexto del Proyecto

### Objetivo
Migrar 8,122 objetos PL/SQL de Oracle 19c a PostgreSQL 17.4 (Amazon Aurora) usando **Claude Code CLI/Web con suscripciÃ³n Pro ($20/mes)** - SIN usar API de Anthropic.

### Estado Actual
```
âœ… COMPLETADO:
- Fase 0: Discovery y anÃ¡lisis de requisitos
- ExtracciÃ³n de 8,122 objetos PL/SQL desde Oracle (sql/extracted/)
- ConversiÃ³n de DDL con ora2pg (sql/exported/)
- DDL ejecutado exitosamente en PostgreSQL

â³ PENDIENTE:
- MigraciÃ³n de cÃ³digo PL/SQL â†’ PL/pgSQL (functions, procedures, packages)
- ValidaciÃ³n de compilaciÃ³n
- Shadow testing (Oracle vs PostgreSQL)
```

---

## ğŸ”¬ Experimentos Realizados (2025-01-05)

### Descubrimiento de Capacidades de Sub-agentes

**Test 1: 3 sub-agentes en paralelo**
- âœ… EXITOSO - Todos completaron sin errores

**Test 2: 10 sub-agentes en paralelo**
- âœ… EXITOSO - Procesaron 172,383 lÃ­neas de cÃ³digo

**Test 3: 20 sub-agentes en paralelo**
- âœ… EXITOSO - Todos los agentes completaron exitosamente

**ConclusiÃ³n:**
- Claude Code soporta al menos 20 sub-agentes en paralelo
- 1 mensaje puede procesar 200+ objetos (20 sub-agentes Ã— 10 objetos cada uno)
- LÃ­mite real mucho mÃ¡s alto de lo documentado oficialmente

### LÃ­mites de SuscripciÃ³n Confirmados

**Claude Code Pro ($20/mes):**
- ~45-60 mensajes cada 5 horas (estimado)
- Contexto: 200K tokens por mensaje
- Contexto por sub-agente: 200K tokens (independiente)
- Sub-agentes en paralelo: 20+ confirmado experimentalmente

**IMPORTANTE:**
- Claude Code CLI y Web comparten los MISMOS lÃ­mites
- El modelo a usar es Claude Sonnet 4.5 (suficiente para anÃ¡lisis de cÃ³digo)

---

## ğŸ”„ Flujo de MigraciÃ³n en 4 Fases

### FASE 1: ANÃLISIS Y CLASIFICACIÃ“N (5 horas - 1 sesiÃ³n)

**Objetivo:** Analizar 8,122 objetos y clasificarlos en SIMPLE vs COMPLEX

**Input:**
```
sql/extracted/
â”œâ”€â”€ functions.sql (146 functions)
â”œâ”€â”€ procedures.sql (196 procedures)
â”œâ”€â”€ packages_spec.sql (589 package specs)
â”œâ”€â”€ packages_body.sql (569 package bodies)
â”œâ”€â”€ triggers.sql (87 triggers)
â”œâ”€â”€ tables.sql (para anÃ¡lisis de dependencias)
â”œâ”€â”€ foreign_keys.sql (para anÃ¡lisis de relaciones)
â””â”€â”€ primary_keys.sql (para anÃ¡lisis de estructura)
```

**Proceso:**
- 20 sub-agentes "plsql-analyzer" en paralelo por mensaje
- 10 objetos por sub-agente = 200 objetos por mensaje
- 42 mensajes para 8,122 objetos
- Tiempo estimado: 5 horas (1 sesiÃ³n)

**Output:**
```
knowledge/
â”œâ”€â”€ json/               # Para base de datos vectorial (pgvector)
â”‚   â””â”€â”€ batch_XXX/
â”‚       â””â”€â”€ obj_XXX_[nombre].json
â”œâ”€â”€ markdown/           # Para lectura humana/IA
â”‚   â””â”€â”€ batch_XXX/
â”‚       â””â”€â”€ obj_XXX_[nombre].md
â””â”€â”€ classification/
    â”œâ”€â”€ simple_objects.txt (~5,000 objetos)
    â”œâ”€â”€ complex_objects.txt (~3,122 objetos)
    â””â”€â”€ summary.json
```

**Criterios de ClasificaciÃ³n:**

**COMPLEX** (migrar con sub-agentes Claude):
- AUTONOMOUS_TRANSACTION
- UTL_HTTP
- UTL_FILE / DIRECTORY
- DBMS_SQL
- TABLE OF INDEX BY / VARRAY
- Motores de fÃ³rmulas dinÃ¡micas
- LÃ³gica muy compleja (50+ reglas)

**SIMPLE** (migrar con ora2pg):
- CÃ³digo estÃ¡ndar PL/SQL
- Sin features Oracle avanzadas
- LÃ³gica directa y clara

---

### FASE 2A: CONVERSIÃ“N SIMPLE con ora2pg (30 minutos)

**Input:** classification/simple_objects.txt (~5,000 objetos)

**Proceso:**
- Ejecutar script bash local: `scripts/convert_simple_objects.sh`
- ora2pg convierte objetos automÃ¡ticamente
- TÃš ejecutas localmente (no Claude)

**Output:**
```
migrated/simple/
â”œâ”€â”€ functions/*.sql
â”œâ”€â”€ procedures/*.sql
â””â”€â”€ packages/*.sql
```

**Costo tokens Claude:** 0 âœ…

---

### FASE 2B: CONVERSIÃ“N COMPLEJA con Sub-agentes (5 horas - 1 sesiÃ³n)

**Input:** classification/complex_objects.txt (~3,122 objetos)

**Proceso:**
- 20 sub-agentes "plsql-converter" en paralelo por mensaje
- 10 objetos complejos por sub-agente = 200 objetos por mensaje
- 16 mensajes para 3,122 objetos
- Tiempo estimado: 5 horas (1 sesiÃ³n)

**Estrategias de ConversiÃ³n por Feature:**

**AUTONOMOUS_TRANSACTION:**
```sql
-- Oracle:
PRAGMA AUTONOMOUS_TRANSACTION;

-- PostgreSQL (opciÃ³n dblink):
PERFORM dblink_exec('dbname=veris_dev', 'BEGIN ... END;');
```

**UTL_HTTP:**
```sql
-- Oracle:
UTL_HTTP.REQUEST('http://api.example.com')

-- PostgreSQL (wrapper + Lambda):
SELECT http_request('GET', 'http://api.example.com');
```

**TABLE OF INDEX BY:**
```sql
-- Oracle:
TYPE t_array IS TABLE OF VARCHAR2(100) INDEX BY BINARY_INTEGER;

-- PostgreSQL:
v_array VARCHAR(100)[]; -- Array nativo
```

**Variables de Paquete:**
```sql
-- Oracle:
v_global := 'value';

-- PostgreSQL:
PERFORM set_config('pkg_name.v_global', 'value', false);
v_global := current_setting('pkg_name.v_global');
```

**Output:**
```
migrated/complex/
â”œâ”€â”€ functions/*.sql
â”œâ”€â”€ procedures/*.sql
â””â”€â”€ packages/*.sql

conversion_log/
â””â”€â”€ [objeto].md (documentaciÃ³n de cambios)
```

---

### FASE 3: VALIDACIÃ“N DE COMPILACIÃ“N (5 horas - 1 sesiÃ³n)

**Input:** migrated/{simple,complex}/**/*.sql (8,122 archivos)

**Proceso:**
- 20 sub-agentes "compilation-validator" en paralelo
- Conectan a PostgreSQL y ejecutan scripts
- Capturan errores y sugieren fixes
- 42 mensajes para validar 8,122 objetos

**Output:**
```
compilation_results/
â”œâ”€â”€ success/*.log (objetos compilados OK)
â””â”€â”€ errors/*.error (objetos con errores + fix sugerido)
```

---

### FASE 4: SHADOW TESTING (10 horas - 2 sesiones)

**Input:** compilation_results/success/*.log

**Proceso:**
- 10 sub-agentes "shadow-tester" en paralelo (mÃ¡s lento)
- Ejecutan mismo cÃ³digo en Oracle y PostgreSQL
- Comparan resultados
- 84 mensajes para testear 8,122 objetos

**Output:**
```
shadow_tests/
â”œâ”€â”€ [objeto].json (comparaciÃ³n de resultados)
â””â”€â”€ discrepancies.txt (diferencias encontradas)
```

**Criterio de Ã‰xito:** >95% de objetos con resultados idÃ©nticos

---

## ğŸ“Š Timeline Completo

```
FASE 1: AnÃ¡lisis y ClasificaciÃ³n
â”œâ”€ SesiÃ³n 1: 8,122 objetos analizados
â”œâ”€ Tiempo: 5 horas
â””â”€ Mensajes: 42

FASE 2A: ConversiÃ³n Simple (ora2pg)
â”œâ”€ EjecuciÃ³n local: 5,000 objetos
â”œâ”€ Tiempo: 30 minutos
â””â”€ Mensajes: 0 âœ…

FASE 2B: ConversiÃ³n Compleja (sub-agentes)
â”œâ”€ SesiÃ³n 2: 3,122 objetos convertidos
â”œâ”€ Tiempo: 5 horas
â””â”€ Mensajes: 16

FASE 3: ValidaciÃ³n CompilaciÃ³n
â”œâ”€ SesiÃ³n 3: 8,122 objetos validados
â”œâ”€ Tiempo: 5 horas
â””â”€ Mensajes: 42

FASE 4: Shadow Testing
â”œâ”€ Sesiones 4-5: 8,122 objetos testeados
â”œâ”€ Tiempo: 10 horas (2 sesiones)
â””â”€ Mensajes: 84

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
TOTAL:
â”œâ”€ Tiempo efectivo: 25.5 horas
â”œâ”€ Sesiones de 5h: 5-6 sesiones
â”œâ”€ Timeline calendario: 2-3 dÃ­as
â”œâ”€ Mensajes Claude: 184 de ~250 disponibles
â””â”€ Margen: 66 mensajes para errores/iteraciones âœ…
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
```

---

## ğŸ—„ï¸ Base de Datos Vectorial (pgvector)

### Objetivo
Almacenar conocimiento de cada objeto analizado para consulta por futuros agentes IA.

### Proceso en 2 Etapas

**Etapa 1: Sub-agentes guardan JSON (Durante anÃ¡lisis)**
- Sub-agentes guardan archivos JSON estructurados
- Campo `embedding_text` contiene resumen para embeddings

**Etapa 2: Script carga a pgvector (DespuÃ©s del anÃ¡lisis)**
```bash
python scripts/load_to_pgvector.py
```

Este script:
- Lee todos los JSON de knowledge/json/
- Genera embeddings con sentence-transformers (local, gratis)
- Carga a PostgreSQL con extensiÃ³n pgvector
- Tiempo: ~15 minutos para 8,122 objetos

### Schema PostgreSQL

```sql
CREATE TABLE plsql_objects (
    id SERIAL PRIMARY KEY,
    object_id VARCHAR(50) UNIQUE,
    object_name VARCHAR(200),
    object_type VARCHAR(50),
    complexity VARCHAR(20),
    full_data JSONB,
    embedding vector(384)
);

CREATE TABLE business_rules (
    id SERIAL PRIMARY KEY,
    object_id VARCHAR(50) REFERENCES plsql_objects(object_id),
    rule_name TEXT,
    description TEXT,
    embedding vector(384)
);
```

### BÃºsqueda SemÃ¡ntica

```sql
-- Buscar objetos relacionados con "cÃ¡lculo de nÃ³mina"
SELECT object_name,
       1 - (embedding <=> query_embedding) as similarity
FROM plsql_objects
ORDER BY embedding <=> query_embedding
LIMIT 10;
```

---

## ğŸ”§ TecnologÃ­as y Herramientas

### Claude Code
- **VersiÃ³n:** Claude Code CLI/Web
- **SuscripciÃ³n:** Claude Code Pro ($20/mes)
- **Modelo:** Claude Sonnet 4.5
- **LÃ­mites:** ~50 mensajes cada 5 horas
- **Sub-agentes en paralelo:** 20 confirmado

### Herramientas Locales (GRATIS)
- **ora2pg:** ConversiÃ³n automÃ¡tica de objetos SIMPLES
- **sentence-transformers:** GeneraciÃ³n de embeddings locales
- **PostgreSQL 17.4 + pgvector:** Base de datos vectorial

### AWS (Ya configurado)
- **Aurora PostgreSQL 17.4:** Base de datos destino
- **S3:** Almacenamiento de archivos (DIRECTORY objects)
- **Lambda:** HTTP client para UTL_HTTP (pendiente crear)

---

## ğŸ¯ PrÃ³ximos Pasos Inmediatos

### 1. Reorganizar Proyecto
- [ ] Evaluar contenido del worktree `.trees/feature-oracle-postgres-migration/`
- [ ] Extraer conocimiento valioso (discovery, decisiones tÃ©cnicas)
- [ ] Eliminar planes obsoletos de Pydantic AI
- [ ] Actualizar estructura del proyecto

### 2. Crear Estructura de Directorios
```bash
mkdir -p knowledge/{json,markdown,classification}
mkdir -p migrated/{simple,complex}/{functions,procedures,packages}
mkdir -p compilation_results/{success,errors}
mkdir -p shadow_tests
mkdir -p conversion_log
mkdir -p scripts
```

### 3. Preparar Scripts
- [ ] `scripts/convert_simple_objects.sh` (ora2pg)
- [ ] `scripts/load_to_pgvector.py` (embeddings)
- [ ] ConfiguraciÃ³n ora2pg

### 4. Iniciar FASE 1
- [ ] Ejecutar anÃ¡lisis de 8,122 objetos con sub-agentes
- [ ] Clasificar en SIMPLE vs COMPLEX
- [ ] Guardar conocimiento en JSON + Markdown

---

## ğŸ“ Notas Importantes

### Â¿Por quÃ© NO usar Pydantic AI?
- Requiere API de Anthropic (~$30-150 USD adicionales)
- NO estÃ¡ incluido en Claude Code Pro
- Claude Code CLI/Web con sub-agentes es suficiente y GRATIS

### Â¿Por quÃ© Sonnet 4.5 en lugar de Opus 4.5?
- Sonnet es excelente para anÃ¡lisis de cÃ³digo estructurado
- MÃ¡s rÃ¡pido que Opus
- Opus solo necesario para razonamiento filosÃ³fico profundo
- PL/SQL tiene sintaxis bien definida (no requiere Opus)

### Â¿CÃ³mo funciona el lÃ­mite de mensajes?
- Comparte entre CLI y Web (NO son separados)
- Se resetea cada 5 horas
- 1 mensaje puede lanzar 20 sub-agentes en paralelo
- Cada sub-agente tiene su propio contexto de 200K tokens

---

## ğŸ”— Referencias

### DocumentaciÃ³n Oficial Consultada
- [Claude Code CLI Documentation](https://code.claude.com/docs/en/)
- [Claude API Rate Limits](https://platform.claude.com/docs/en/api/rate-limits.md)
- [Sub-agents Documentation](https://code.claude.com/docs/en/sub-agents.md)

### Conocimiento Preservado de Discovery
Ver archivos en `.claude/sessions/oracle-postgres-migration/`:
- `00_index.md` - Resumen ejecutivo
- `01_problem_statement.md` - 5W1H + JTBD + Scope
- `02_user_stories.md` - Ã‰picas + User Stories
- `04_decisions.md` - Decisiones tÃ©cnicas (AUTONOMOUS_TRANSACTION, UTL_HTTP, etc.)

---

**Ãšltima actualizaciÃ³n:** 2025-01-05 por Claude Sonnet 4.5
**PrÃ³xima revisiÃ³n:** DespuÃ©s de completar FASE 1

---

## âš ï¸ ADVERTENCIA: Framework Context Flow Optimization

El framework "Context Flow Optimization" instalado en `.claude/CLAUDE.md` y los planes en `.trees/feature-oracle-postgres-migration/` fueron diseÃ±ados para:
- Aplicaciones Pydantic AI autÃ³nomas
- Uso de API de Anthropic (pago por tokens)
- Agentes ejecutados fuera de Claude Code

**Este framework YA NO aplica** para la estrategia actual que usa:
- Claude Code CLI/Web directamente
- Sub-agentes nativos de Claude Code
- SuscripciÃ³n Claude Code Pro

Se recomienda:
1. Preservar discovery documents (conocimiento valioso)
2. Eliminar/archivar planes de Pydantic AI (obsoletos)
3. Actualizar `.claude/CLAUDE.md` con estrategia actual
